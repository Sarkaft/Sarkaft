{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVIz/yr30VQrfkatfSp4fa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sarkaft/Sarkaft/blob/main/privateGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WJiiI8jWff4",
        "outputId": "2ed6d77b-0bab-4bb0-cf0d-ea7b89281a40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'privateGPT'...\n",
            "remote: Enumerating objects: 279, done.\u001b[K\n",
            "remote: Counting objects: 100% (183/183), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 279 (delta 150), reused 103 (delta 103), pack-reused 96\u001b[K\n",
            "Receiving objects: 100% (279/279), 92.55 KiB | 1.30 MiB/s, done.\n",
            "Resolving deltas: 100% (155/155), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/imartinez/privateGPT.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd privateGPT/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZHRnq1TWwAG",
        "outputId": "8b858eec-fc46-4485-b8c6-50cbf8991498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/privateGPT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lxIwt62LYqh-",
        "outputId": "29306dd2-d273-4bae-8db3-d927e16982d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain==0.0.177 (from -r requirements.txt (line 1))\n",
            "  Downloading langchain-0.0.177-py3-none-any.whl (877 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m877.7/877.7 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpt4all==0.2.3 (from -r requirements.txt (line 2))\n",
            "  Downloading gpt4all-0.2.3-py3-none-manylinux1_x86_64.whl (329 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.1/329.1 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chromadb==0.3.23 (from -r requirements.txt (line 3))\n",
            "  Downloading chromadb-0.3.23-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.3/71.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-cpp-python==0.1.50 (from -r requirements.txt (line 4))\n",
            "  Downloading llama_cpp_python-0.1.50.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting urllib3==2.0.2 (from -r requirements.txt (line 5))\n",
            "  Downloading urllib3-2.0.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.2/123.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20221105 (from -r requirements.txt (line 6))\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv==1.0.0 (from -r requirements.txt (line 7))\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting unstructured==0.6.6 (from -r requirements.txt (line 8))\n",
            "  Downloading unstructured-0.6.6-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting extract-msg==0.41.1 (from -r requirements.txt (line 9))\n",
            "  Downloading extract_msg-0.41.1-py2.py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tabulate==0.9.0 (from -r requirements.txt (line 10))\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Collecting pandoc==2.3 (from -r requirements.txt (line 11))\n",
            "  Downloading pandoc-2.3.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pypandoc==1.11 (from -r requirements.txt (line 12))\n",
            "  Downloading pypandoc-1.11-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: tqdm==4.65.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.177->-r requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.177->-r requirements.txt (line 1)) (2.0.10)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.0.177->-r requirements.txt (line 1))\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0 (from langchain==0.0.177->-r requirements.txt (line 1))\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.177->-r requirements.txt (line 1))\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.177->-r requirements.txt (line 1)) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.177->-r requirements.txt (line 1)) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.177->-r requirements.txt (line 1))\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.177->-r requirements.txt (line 1)) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.177->-r requirements.txt (line 1)) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.177->-r requirements.txt (line 1)) (8.2.2)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.23->-r requirements.txt (line 3)) (1.5.3)\n",
            "Collecting requests<3,>=2 (from langchain==0.0.177->-r requirements.txt (line 1))\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hnswlib>=0.7 (from chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading hnswlib-0.7.0.tar.gz (33 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting clickhouse-connect>=0.5.7 (from chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading clickhouse_connect-0.5.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.7/922.7 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers>=2.2.2 (from chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: duckdb>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.23->-r requirements.txt (line 3)) (0.7.1)\n",
            "Collecting fastapi>=0.85.1 (from chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading fastapi-0.95.2-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.23->-r requirements.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->-r requirements.txt (line 6)) (2.0.12)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->-r requirements.txt (line 6)) (40.0.2)\n",
            "Collecting argilla (from unstructured==0.6.6->-r requirements.txt (line 8))\n",
            "  Downloading argilla-1.7.0-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured==0.6.6->-r requirements.txt (line 8)) (4.9.2)\n",
            "Collecting msg-parser (from unstructured==0.6.6->-r requirements.txt (line 8))\n",
            "  Downloading msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured==0.6.6->-r requirements.txt (line 8)) (3.8.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from unstructured==0.6.6->-r requirements.txt (line 8)) (3.0.10)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unstructured==0.6.6->-r requirements.txt (line 8)) (8.4.0)\n",
            "Collecting python-docx (from unstructured==0.6.6->-r requirements.txt (line 8))\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-pptx (from unstructured==0.6.6->-r requirements.txt (line 8))\n",
            "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-magic (from unstructured==0.6.6->-r requirements.txt (line 8))\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured==0.6.6->-r requirements.txt (line 8)) (3.4.3)\n",
            "Requirement already satisfied: certifi>=2022.12.07 in /usr/local/lib/python3.10/dist-packages (from unstructured==0.6.6->-r requirements.txt (line 8)) (2022.12.7)\n",
            "Collecting imapclient<3,>=2.3.0 (from extract-msg==0.41.1->-r requirements.txt (line 9))\n",
            "  Downloading IMAPClient-2.3.1-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting olefile==0.46 (from extract-msg==0.41.1->-r requirements.txt (line 9))\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tzlocal==4.2 (from extract-msg==0.41.1->-r requirements.txt (line 9))\n",
            "  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n",
            "Collecting compressed-rtf==1.0.6 (from extract-msg==0.41.1->-r requirements.txt (line 9))\n",
            "  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ebcdic==1.1.1 (from extract-msg==0.41.1->-r requirements.txt (line 9))\n",
            "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.5/128.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<4.13,>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from extract-msg==0.41.1->-r requirements.txt (line 9)) (4.11.2)\n",
            "Collecting RTFDE==0.0.2 (from extract-msg==0.41.1->-r requirements.txt (line 9))\n",
            "  Downloading RTFDE-0.0.2-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: chardet<6,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from extract-msg==0.41.1->-r requirements.txt (line 9)) (4.0.0)\n",
            "Collecting red-black-tree-mod==1.20 (from extract-msg==0.41.1->-r requirements.txt (line 9))\n",
            "  Downloading red-black-tree-mod-1.20.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting plumbum (from pandoc==2.3->-r requirements.txt (line 11))\n",
            "  Downloading plumbum-1.8.1-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ply (from pandoc==2.3->-r requirements.txt (line 11))\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lark-parser>=0.11 (from RTFDE==0.0.2->extract-msg==0.41.1->-r requirements.txt (line 9))\n",
            "  Downloading lark_parser-0.12.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting oletools>=0.56 (from RTFDE==0.0.2->extract-msg==0.41.1->-r requirements.txt (line 9))\n",
            "  Downloading oletools-0.60.1-py2.py3-none-any.whl (977 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m977.2/977.2 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal==4.2->extract-msg==0.41.1->-r requirements.txt (line 9)) (0.1.0.post0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.177->-r requirements.txt (line 1)) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.177->-r requirements.txt (line 1))\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.177->-r requirements.txt (line 1))\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.177->-r requirements.txt (line 1))\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.177->-r requirements.txt (line 1))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<4.13,>=4.11.1->extract-msg==0.41.1->-r requirements.txt (line 9)) (2.4.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.23->-r requirements.txt (line 3)) (2022.7.1)\n",
            "Collecting zstandard (from clickhouse-connect>=0.5.7->chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lz4 (from clickhouse-connect>=0.5.7->chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->-r requirements.txt (line 6)) (1.15.1)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.177->-r requirements.txt (line 1))\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.177->-r requirements.txt (line 1))\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.177->-r requirements.txt (line 1))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi>=0.85.1->chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imapclient<3,>=2.3.0->extract-msg==0.41.1->-r requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb==0.3.23->-r requirements.txt (line 3)) (2.8.2)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.177->-r requirements.txt (line 1)) (3.4)\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3)) (0.15.2+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3)) (1.10.1)\n",
            "Collecting sentencepiece (from sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.177->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.23->-r requirements.txt (line 3)) (8.1.3)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading httptools-0.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (414 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.1/414.1 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading watchfiles-0.19.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx<0.24,>=0.15 (from argilla->unstructured==0.6.6->-r requirements.txt (line 8))\n",
            "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecated~=1.2.0 (from argilla->unstructured==0.6.6->-r requirements.txt (line 8))\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured==0.6.6->-r requirements.txt (line 8)) (23.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.13 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured==0.6.6->-r requirements.txt (line 8)) (1.14.1)\n",
            "Collecting rich<=13.0.1 (from argilla->unstructured==0.6.6->-r requirements.txt (line 8))\n",
            "  Downloading rich-13.0.1-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.1/238.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer<1.0.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured==0.6.6->-r requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.6.6->-r requirements.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.6.6->-r requirements.txt (line 8)) (2022.10.31)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->unstructured==0.6.6->-r requirements.txt (line 8)) (1.1.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx->unstructured==0.6.6->-r requirements.txt (line 8))\n",
            "  Downloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->-r requirements.txt (line 6)) (2.21)\n",
            "Collecting httpcore<0.17.0,>=0.15.0 (from httpx<0.24,>=0.15->argilla->unstructured==0.6.6->-r requirements.txt (line 8))\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3 (from httpx<0.24,>=0.15->argilla->unstructured==0.6.6->-r requirements.txt (line 8))\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured==0.6.6->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3)) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3)) (2023.4.0)\n",
            "Collecting pyparsing<3,>=2.1.0 (from oletools>=0.56->RTFDE==0.0.2->extract-msg==0.41.1->-r requirements.txt (line 9))\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting easygui (from oletools>=0.56->RTFDE==0.0.2->extract-msg==0.41.1->-r requirements.txt (line 9))\n",
            "  Downloading easygui-0.98.3-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorclass (from oletools>=0.56->RTFDE==0.0.2->extract-msg==0.41.1->-r requirements.txt (line 9))\n",
            "  Downloading colorclass-2.2.2-py2.py3-none-any.whl (18 kB)\n",
            "Collecting pcodedmp>=1.2.5 (from oletools>=0.56->RTFDE==0.0.2->extract-msg==0.41.1->-r requirements.txt (line 9))\n",
            "  Downloading pcodedmp-1.2.6-py2.py3-none-any.whl (30 kB)\n",
            "Collecting msoffcrypto-tool (from oletools>=0.56->RTFDE==0.0.2->extract-msg==0.41.1->-r requirements.txt (line 9))\n",
            "  Downloading msoffcrypto_tool-5.0.1-py3-none-any.whl (34 kB)\n",
            "Collecting commonmark<0.10.0,>=0.9.0 (from rich<=13.0.1->argilla->unstructured==0.6.6->-r requirements.txt (line 8))\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich<=13.0.1->argilla->unstructured==0.6.6->-r requirements.txt (line 8)) (2.14.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb==0.3.23->-r requirements.txt (line 3)) (3.6.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3)) (16.0.5)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.177->-r requirements.txt (line 1))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal==4.2->extract-msg==0.41.1->-r requirements.txt (line 9)) (2023.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3)) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb==0.3.23->-r requirements.txt (line 3)) (1.3.0)\n",
            "Building wheels for collected packages: llama-cpp-python, pandoc, compressed-rtf, olefile, red-black-tree-mod, hnswlib, sentence-transformers, python-docx, python-pptx\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.50-cp310-cp310-linux_x86_64.whl size=204117 sha256=2430faf0b52739b405e5abb819cc8d675d8d495ececb0da46cda324b546b5268\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/26/7a/d5f3e9cc210a00274eb9648b6d7d530ae2923b57c43b408a5e\n",
            "  Building wheel for pandoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandoc: filename=pandoc-2.3-py3-none-any.whl size=33262 sha256=b8cfa35782aa51a41e8d4dd007be926da189f1dd8dab6464c13e8b4841242509\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/27/c2/c26175310aadcb8741b77657a1bb49c50cc7d4cdbf9eee0005\n",
            "  Building wheel for compressed-rtf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6185 sha256=7b48cdd76335d4b1dcaae6e835f010d9223a95d55867f51954149d1adf908a0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/3e/48/e7d833ecc516c36f8966d310b1a6386db091a718f1ff3bf85c\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35417 sha256=03a8ae90ca56a243f7bc9ec2a2ea421d2dbbf33bbe2c7f50aeae612331de4a46\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/39/c0/9eb1f7a42b4b38f6f333b6314d4ed11c46f12a0f7b78194f0d\n",
            "  Building wheel for red-black-tree-mod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for red-black-tree-mod: filename=red_black_tree_mod-1.20-py3-none-any.whl size=18623 sha256=9004552ccc7d91d3208d7bca6e40bb18c2dc9d176be32efb70a826f149210da4\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/89/a0/17d08e78a59e4e8f51a95fe52e19c6916450c143acc7bce4dd\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp310-cp310-linux_x86_64.whl size=2122067 sha256=3b448ca940a8eb4c0cbf9f089a6f6e305ed43f8f83366ea8c71ac9ea4f50c9ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/ae/ec/235a682e0041fbaeee389843670581ec6c66872db856dfa9a4\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=75ca9724ab3fd6208eb8ecd2d9c64e65bea56acfbf6c62a3282a03df794c74b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184491 sha256=e20576034ef88a2d5dcc40607e2ee2c59a5ebcd0d0226450bee3333fb79826cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470935 sha256=6fbf9e8fdc7299d7f4af3194b9a59987bf1905d7dc1ce28cb384c6f8c2a656f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/dd/74/01b3ec7256a0800b99384e9a0f7620e358afc3a51a59bf9b49\n",
            "Successfully built llama-cpp-python pandoc compressed-rtf olefile red-black-tree-mod hnswlib sentence-transformers python-docx python-pptx\n",
            "Installing collected packages: tokenizers, sentencepiece, rfc3986, red-black-tree-mod, ply, monotonic, lark-parser, ebcdic, easygui, compressed-rtf, commonmark, zstandard, XlsxWriter, websockets, uvloop, urllib3, tabulate, rich, python-magic, python-dotenv, python-docx, pyparsing, pypandoc, plumbum, olefile, mypy-extensions, multidict, marshmallow, lz4, llama-cpp-python, imapclient, httptools, hnswlib, h11, frozenlist, deprecated, colorclass, backoff, async-timeout, yarl, watchfiles, uvicorn, tzlocal, typing-inspect, starlette, requests, python-pptx, pandoc, openapi-schema-pydantic, msg-parser, marshmallow-enum, httpcore, clickhouse-connect, aiosignal, posthog, pdfminer.six, msoffcrypto-tool, huggingface-hub, httpx, gpt4all, fastapi, dataclasses-json, aiohttp, transformers, langchain, argilla, unstructured, pcodedmp, oletools, sentence-transformers, RTFDE, extract-msg, chromadb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.15\n",
            "    Uninstalling urllib3-1.26.15:\n",
            "      Successfully uninstalled urllib3-1.26.15\n",
            "  Attempting uninstall: tabulate\n",
            "    Found existing installation: tabulate 0.8.10\n",
            "    Uninstalling tabulate-0.8.10:\n",
            "      Successfully uninstalled tabulate-0.8.10\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.3.4\n",
            "    Uninstalling rich-13.3.4:\n",
            "      Successfully uninstalled rich-13.3.4\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: tzlocal\n",
            "    Found existing installation: tzlocal 4.3\n",
            "    Uninstalling tzlocal-4.3:\n",
            "      Successfully uninstalled tzlocal-4.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed RTFDE-0.0.2 XlsxWriter-3.1.2 aiohttp-3.8.4 aiosignal-1.3.1 argilla-1.7.0 async-timeout-4.0.2 backoff-2.2.1 chromadb-0.3.23 clickhouse-connect-0.5.25 colorclass-2.2.2 commonmark-0.9.1 compressed-rtf-1.0.6 dataclasses-json-0.5.7 deprecated-1.2.14 easygui-0.98.3 ebcdic-1.1.1 extract-msg-0.41.1 fastapi-0.95.2 frozenlist-1.3.3 gpt4all-0.2.3 h11-0.14.0 hnswlib-0.7.0 httpcore-0.16.3 httptools-0.5.0 httpx-0.23.3 huggingface-hub-0.14.1 imapclient-2.3.1 langchain-0.0.177 lark-parser-0.12.0 llama-cpp-python-0.1.50 lz4-4.3.2 marshmallow-3.19.0 marshmallow-enum-1.5.1 monotonic-1.6 msg-parser-1.2.0 msoffcrypto-tool-5.0.1 multidict-6.0.4 mypy-extensions-1.0.0 olefile-0.46 oletools-0.60.1 openapi-schema-pydantic-1.2.4 pandoc-2.3 pcodedmp-1.2.6 pdfminer.six-20221105 plumbum-1.8.1 ply-3.11 posthog-3.0.1 pypandoc-1.11 pyparsing-2.4.7 python-docx-0.8.11 python-dotenv-1.0.0 python-magic-0.4.27 python-pptx-0.6.21 red-black-tree-mod-1.20 requests-2.31.0 rfc3986-1.5.0 rich-13.0.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 starlette-0.27.0 tabulate-0.9.0 tokenizers-0.13.3 transformers-4.29.2 typing-inspect-0.9.0 tzlocal-4.2 unstructured-0.6.6 urllib3-2.0.2 uvicorn-0.22.0 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.3 yarl-1.9.2 zstandard-0.21.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyparsing",
                  "requests"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr8lfkylZP6o",
        "outputId": "9c0dc699-4430-4169-d20b-fbc4f76368d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-29 07:24:55--  https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin\n",
            "Resolving gpt4all.io (gpt4all.io)... 104.26.1.159, 172.67.71.169, 104.26.0.159, ...\n",
            "Connecting to gpt4all.io (gpt4all.io)|104.26.1.159|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3785248281 (3.5G)\n",
            "Saving to: ‘ggml-gpt4all-j-v1.3-groovy.bin’\n",
            "\n",
            "ggml-gpt4all-j-v1.3 100%[===================>]   3.52G  56.1MB/s    in 71s     \n",
            "\n",
            "2023-05-29 07:26:07 (50.7 MB/s) - ‘ggml-gpt4all-j-v1.3-groovy.bin’ saved [3785248281/3785248281]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ingest.py"
      ],
      "metadata": {
        "id": "Ap-zrMeHaIuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed296fca-12d3-44c8-de21-c31e979ce6c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rDownloading (…)e9125/.gitattributes:   0% 0.00/1.18k [00:00<?, ?B/s]\rDownloading (…)e9125/.gitattributes: 100% 1.18k/1.18k [00:00<00:00, 5.22MB/s]\n",
            "Downloading (…)_Pooling/config.json: 100% 190/190 [00:00<00:00, 783kB/s]\n",
            "Downloading (…)7e55de9125/README.md: 100% 10.6k/10.6k [00:00<00:00, 40.4MB/s]\n",
            "Downloading (…)55de9125/config.json: 100% 612/612 [00:00<00:00, 2.68MB/s]\n",
            "Downloading (…)ce_transformers.json: 100% 116/116 [00:00<00:00, 524kB/s]\n",
            "Downloading (…)125/data_config.json: 100% 39.3k/39.3k [00:00<00:00, 81.3MB/s]\n",
            "Downloading pytorch_model.bin: 100% 90.9M/90.9M [00:00<00:00, 185MB/s]\n",
            "Downloading (…)nce_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 216kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 112/112 [00:00<00:00, 431kB/s]\n",
            "Downloading (…)e9125/tokenizer.json: 100% 466k/466k [00:00<00:00, 1.89MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 350/350 [00:00<00:00, 1.43MB/s]\n",
            "Downloading (…)9125/train_script.py: 100% 13.2k/13.2k [00:00<00:00, 47.3MB/s]\n",
            "Downloading (…)7e55de9125/vocab.txt: 100% 232k/232k [00:00<00:00, 2.85MB/s]\n",
            "Downloading (…)5de9125/modules.json: 100% 349/349 [00:00<00:00, 1.30MB/s]\n",
            "Creating new vectorstore\n",
            "Loading documents from source_documents\n",
            "Loading new documents: 100%|██████████████████████| 2/2 [00:08<00:00,  4.26s/it]\n",
            "Loaded 2 new documents from source_documents\n",
            "Split into 90 chunks of text (max. 500 tokens each)\n",
            "Creating embeddings. May take some minutes...\n",
            "Using embedded DuckDB with persistence: data will be stored in: db\n",
            "Ingestion complete! You can now run privateGPT.py to query your documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python privateGPT.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AID8tas8dSQv",
        "outputId": "3dd52c55-1501-43e2-a894-9a7731390c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using embedded DuckDB with persistence: data will be stored in: db\n",
            "Found model file.\n",
            "gptj_model_load: loading model from 'models/ggml-gpt4all-j-v1.3-groovy.bin' - please wait ...\n",
            "gptj_model_load: n_vocab = 50400\n",
            "gptj_model_load: n_ctx   = 2048\n",
            "gptj_model_load: n_embd  = 4096\n",
            "gptj_model_load: n_head  = 16\n",
            "gptj_model_load: n_layer = 28\n",
            "gptj_model_load: n_rot   = 64\n",
            "gptj_model_load: f16     = 2\n",
            "gptj_model_load: ggml ctx size = 5401.45 MB\n",
            "gptj_model_load: kv self size  =  896.00 MB\n",
            "gptj_model_load: ................................... done\n",
            "gptj_model_load: model size =  3609.38 MB / num tensors = 285\n",
            "\n",
            "Enter a query: salahaddin genomic\n",
            "hi\n",
            " I don't know any information about a person named Salahaddin or his genome testing services\n",
            " I don't know any information about a person named Salahaddin or his genome testing services\n",
            "\n",
            "> Question:\n",
            "salahaddin genomic\n",
            "\n",
            "> Answer:\n",
            " I don't know any information about a person named Salahaddin or his genome testing services\n",
            "\n",
            "> source_documents/state_of_the_union.txt:\n",
            "More support for patients and families. \n",
            "\n",
            "To get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \n",
            "\n",
            "It’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \n",
            "\n",
            "ARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more. \n",
            "\n",
            "A unity agenda for the nation. \n",
            "\n",
            "We can do this. \n",
            "\n",
            "My fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy.\n",
            "\n",
            "> source_documents/state_of_the_union.txt:\n",
            "Second – we must prepare for new variants. Over the past year, we’ve gotten much better at detecting new variants. \n",
            "\n",
            "If necessary, we’ll be able to deploy new vaccines within 100 days instead of many more months or years.  \n",
            "\n",
            "And, if Congress provides the funds we need, we’ll have new stockpiles of tests, masks, and pills ready if needed. \n",
            "\n",
            "I cannot promise a new variant won’t come. But I can promise you we’ll do everything within our power to be ready if it does.\n",
            "\n",
            "> source_documents/state_of_the_union.txt:\n",
            "If you’re immunocompromised or have some other vulnerability, we have treatments and free high-quality masks. \n",
            "\n",
            "We’re leaving no one behind or ignoring anyone’s needs as we move forward. \n",
            "\n",
            "And on testing, we have made hundreds of millions of tests available for you to order for free.   \n",
            "\n",
            "Even if you already ordered free tests tonight, I am announcing that you can order more from covidtests.gov starting next week.\n",
            "\n",
            "> source_documents/state_of_the_union.txt:\n",
            "He and his Dad both have Type 1 diabetes, which means they need insulin every day. Insulin costs about $10 a vial to make.  \n",
            "\n",
            "But drug companies charge families like Joshua and his Dad up to 30 times more. I spoke with Joshua’s mom. \n",
            "\n",
            "Imagine what it’s like to look at your child who needs insulin and have no idea how you’re going to pay for it.  \n",
            "\n",
            "What it does to your dignity, your ability to look your child in the eye, to be the parent you expect to be.\n",
            "\n",
            "Enter a query:  Hi! I'm here to help you with any questions or topics that interest\n",
            " Hi! I'm here to help you with any questions or topics that interest\n",
            "\n",
            "> Question:\n",
            "hi\n",
            "\n",
            "> Answer:\n",
            " Hi! I'm here to help you with any questions or topics that interest\n",
            "\n",
            "> source_documents/state_of_the_union.txt:\n",
            "Now is our moment to meet and overcome the challenges of our time. \n",
            "\n",
            "And we will, as one people. \n",
            "\n",
            "One America. \n",
            "\n",
            "The United States of America. \n",
            "\n",
            "May God bless you all. May God protect our troops.\n",
            "\n",
            "> source_documents/state_of_the_union.txt:\n",
            "Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n",
            "\n",
            "Last year COVID-19 kept us apart. This year we are finally together again. \n",
            "\n",
            "Tonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \n",
            "\n",
            "With a duty to one another to the American people to the Constitution. \n",
            "\n",
            "And with an unwavering resolve that freedom will always triumph over tyranny.\n",
            "\n",
            "> source_documents/state_of_the_union.txt:\n",
            "More support for patients and families. \n",
            "\n",
            "To get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \n",
            "\n",
            "It’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \n",
            "\n",
            "ARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more. \n",
            "\n",
            "A unity agenda for the nation. \n",
            "\n",
            "We can do this. \n",
            "\n",
            "My fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy.\n",
            "\n",
            "> source_documents/state_of_the_union.txt:\n",
            "And soon, we’ll strengthen the Violence Against Women Act that I first wrote three decades ago. It is important for us to show the nation that we can come together and do big things. \n",
            "\n",
            "So tonight I’m offering a Unity Agenda for the Nation. Four big things we can do together.  \n",
            "\n",
            "First, beat the opioid epidemic. \n",
            "\n",
            "There is so much we can do. Increase funding for prevention, treatment, harm reduction, and recovery.\n",
            "\n",
            "Enter a query: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E3FBNYu5dSDe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}